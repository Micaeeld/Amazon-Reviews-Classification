{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üìö Imports\n---","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport string\nimport collections\nimport matplotlib.pyplot as plt\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer, SnowballStemmer\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:19:34.169426Z","iopub.execute_input":"2023-05-02T12:19:34.170424Z","iopub.status.idle":"2023-05-02T12:19:42.921864Z","shell.execute_reply.started":"2023-05-02T12:19:34.170362Z","shell.execute_reply":"2023-05-02T12:19:42.920912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üìñ Data \n---","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/amazon-reviews/train.csv')\ndf_test = pd.read_csv('/kaggle/input/amazon-reviews/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:19:42.925430Z","iopub.execute_input":"2023-05-02T12:19:42.926860Z","iopub.status.idle":"2023-05-02T12:20:23.329172Z","shell.execute_reply.started":"2023-05-02T12:19:42.926822Z","shell.execute_reply":"2023-05-02T12:20:23.328224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:20:23.330593Z","iopub.execute_input":"2023-05-02T12:20:23.330928Z","iopub.status.idle":"2023-05-02T12:20:23.350794Z","shell.execute_reply.started":"2023-05-02T12:20:23.330900Z","shell.execute_reply":"2023-05-02T12:20:23.349970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:20:23.353200Z","iopub.execute_input":"2023-05-02T12:20:23.353645Z","iopub.status.idle":"2023-05-02T12:20:23.376647Z","shell.execute_reply.started":"2023-05-02T12:20:23.353615Z","shell.execute_reply":"2023-05-02T12:20:23.375823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insert columns","metadata":{}},{"cell_type":"code","source":"df_train.columns = ['label', 'title', 'text']\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:20:23.377915Z","iopub.execute_input":"2023-05-02T12:20:23.378212Z","iopub.status.idle":"2023-05-02T12:20:23.388696Z","shell.execute_reply.started":"2023-05-02T12:20:23.378185Z","shell.execute_reply":"2023-05-02T12:20:23.387482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.columns = ['label', 'title', 'text']\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:20:23.390513Z","iopub.execute_input":"2023-05-02T12:20:23.390878Z","iopub.status.idle":"2023-05-02T12:20:23.402468Z","shell.execute_reply.started":"2023-05-02T12:20:23.390848Z","shell.execute_reply":"2023-05-02T12:20:23.401319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using only 50,000 texts for training and 5,000 for validation (anything I raise)","metadata":{}},{"cell_type":"code","source":"df_train = df_train.head(100000)\ndf_test = df_test.head(10000)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:20:23.403982Z","iopub.execute_input":"2023-05-02T12:20:23.404569Z","iopub.status.idle":"2023-05-02T12:20:23.411405Z","shell.execute_reply.started":"2023-05-02T12:20:23.404535Z","shell.execute_reply":"2023-05-02T12:20:23.410548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_train['label'].value_counts())\nprint(df_test['label'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:20:23.413010Z","iopub.execute_input":"2023-05-02T12:20:23.413618Z","iopub.status.idle":"2023-05-02T12:20:23.423700Z","shell.execute_reply.started":"2023-05-02T12:20:23.413587Z","shell.execute_reply":"2023-05-02T12:20:23.422779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### I'll join the title with the text because I think the title is shorter, people tend to put keywords in it","metadata":{}},{"cell_type":"code","source":"def concat_columns(df, col1, col2, new_col):\n    df[new_col] = df[col1].apply(str) + ' ' + df[col2].apply(str)\n    df.drop(col2, axis = 1, inplace = True)\n    return df\n\ndf_train = concat_columns(df_train, 'text', 'title', 'text')\ndf_test = concat_columns(df_test, 'text', 'title', 'text')","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:20:23.425175Z","iopub.execute_input":"2023-05-02T12:20:23.425686Z","iopub.status.idle":"2023-05-02T12:20:23.640917Z","shell.execute_reply.started":"2023-05-02T12:20:23.425657Z","shell.execute_reply":"2023-05-02T12:20:23.639844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### I will change the 'label' column values to 1 -> 0 and 2 -> 1","metadata":{}},{"cell_type":"code","source":"df_train['label'] = df_train['label'].map({1:0, 2:1})\ndf_test['label'] = df_test['label'].map({1:0, 2:1})","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:20:23.644935Z","iopub.execute_input":"2023-05-02T12:20:23.645467Z","iopub.status.idle":"2023-05-02T12:20:23.654515Z","shell.execute_reply.started":"2023-05-02T12:20:23.645435Z","shell.execute_reply":"2023-05-02T12:20:23.653426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:20:23.658398Z","iopub.execute_input":"2023-05-02T12:20:23.659479Z","iopub.status.idle":"2023-05-02T12:20:23.671063Z","shell.execute_reply.started":"2023-05-02T12:20:23.659348Z","shell.execute_reply":"2023-05-02T12:20:23.670005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now the data is ready for cleaning.","metadata":{}},{"cell_type":"markdown","source":"# ‚ôªÔ∏è Data Cleaning\n---","metadata":{}},{"cell_type":"markdown","source":"## Function to remove unwanted characters","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n    # Remove special characters and numbers\n    text = re.sub(r'[^A-Za-z√Ä-√∫ ]+', '', text)\n    # Analyzing the most used words below, i chose to exclude these because there are too many and are unnecessary\n    text = re.sub('book|one', '', text)\n    # Convert to lower case\n    text = text.lower()\n    # remove scores\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    # Remove extra whitespace\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\n# Applying the function\ndf_train['text'] = df_train['text'].apply(clean_text)\ndf_test['text'] = df_test['text'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:20:23.672881Z","iopub.execute_input":"2023-05-02T12:20:23.673184Z","iopub.status.idle":"2023-05-02T12:20:28.613829Z","shell.execute_reply.started":"2023-05-02T12:20:23.673155Z","shell.execute_reply":"2023-05-02T12:20:28.612847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function to remove stop words","metadata":{}},{"cell_type":"code","source":"def remove_stopwords(texto):\n    stop_words = set(stopwords.words('english'))\n    tokens = nltk.word_tokenize(texto.lower())\n    return \" \".join([token for token in tokens if token not in stop_words])\n\n# Applying the function\ndf_train['text'] = df_train['text'].apply(remove_stopwords)\ndf_test['text'] = df_test['text'].apply(remove_stopwords)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:20:28.615475Z","iopub.execute_input":"2023-05-02T12:20:28.615804Z","iopub.status.idle":"2023-05-02T12:21:23.099483Z","shell.execute_reply.started":"2023-05-02T12:20:28.615775Z","shell.execute_reply":"2023-05-02T12:21:23.098585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function to normalize the words","metadata":{}},{"cell_type":"code","source":"def normalize_text(text):\n    stemmer = SnowballStemmer(\"english\")\n    normalized_text = []\n    for word in text.split():\n        stemmed_word = stemmer.stem(word)\n        normalized_text.append(stemmed_word)\n    return ' '.join(normalized_text)\n    \n# Applying the function\ndf_train['text'] = df_train['text'].apply(normalize_text)\ndf_test['text'] = df_test['text'].apply(normalize_text)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:21:23.100805Z","iopub.execute_input":"2023-05-02T12:21:23.101132Z","iopub.status.idle":"2023-05-02T12:22:23.295749Z","shell.execute_reply.started":"2023-05-02T12:21:23.101104Z","shell.execute_reply":"2023-05-02T12:22:23.294767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üìä Top 10 most used words\n---","metadata":{}},{"cell_type":"markdown","source":"## Train data","metadata":{}},{"cell_type":"code","source":"words = []\nfor text in df_train['text']:\n    words.extend(text.split())\nword_count = collections.Counter(words)\ntop_words = dict(word_count.most_common(10))\n\n# Figure Size\nplt.figure(figsize = (10, 6))\n\n# Create the Barplot\nplt.bar(range(len(top_words)), list(top_words.values()), align = 'center')\n\n# Creating a y axis with words\nplt.xticks(range(len(top_words)), list(top_words.keys()))\n\n# Grid Opacity\nplt.grid(alpha = 0.5)\n\n# Title and labels\nplt.title('Top 10 most used words', fontsize = 18)\nplt.xlabel('Words')\nplt.ylabel('Frequency')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-05-02T12:22:23.297188Z","iopub.execute_input":"2023-05-02T12:22:23.297540Z","iopub.status.idle":"2023-05-02T12:22:24.604291Z","shell.execute_reply.started":"2023-05-02T12:22:23.297511Z","shell.execute_reply":"2023-05-02T12:22:24.603294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test data","metadata":{}},{"cell_type":"code","source":"words = []\nfor text in df_test['text']:\n    words.extend(text.split())\nword_count = collections.Counter(words)\ntop_words = dict(word_count.most_common(10))\n\n# Figure Size\nplt.figure(figsize = (10, 6))\n\n# Create the Barplot\nplt.bar(range(len(top_words)), list(top_words.values()), align = 'center')\n\n# Creating a y axis with words\nplt.xticks(range(len(top_words)), list(top_words.keys()))\n\n# Grid Opacity\nplt.grid(alpha = 0.5)\n# Title and labels\nplt.title('Top 10 most used words', fontsize = 18)\nplt.xlabel('Words')\nplt.ylabel('Frequency')","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:22:24.605702Z","iopub.execute_input":"2023-05-02T12:22:24.606036Z","iopub.status.idle":"2023-05-02T12:22:25.052102Z","shell.execute_reply.started":"2023-05-02T12:22:24.606003Z","shell.execute_reply":"2023-05-02T12:22:25.051194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # üß¨ Text processing\n ---","metadata":{}},{"cell_type":"code","source":"# Maximum number of words to be considered in the vocabulary\nmax_words = 10000 \n# Maximum number of tokens in a sequence\nmax_len = 200 \n# Tokenizer\ntokenizer = Tokenizer(num_words = max_words) \n# Snap tokenizer to text data\ntokenizer.fit_on_texts(df_train['text']) \n# Converts texts into strings of numbers\nsequences_train = tokenizer.texts_to_sequences(df_train['text']) \nsequences_val = tokenizer.texts_to_sequences(df_test['text']) \n# Mapping words to indexes\nword_index = tokenizer.word_index ","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:22:25.056217Z","iopub.execute_input":"2023-05-02T12:22:25.058329Z","iopub.status.idle":"2023-05-02T12:22:32.168711Z","shell.execute_reply.started":"2023-05-02T12:22:25.058294Z","shell.execute_reply":"2023-05-02T12:22:32.167782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sequence padding\ndata_train = pad_sequences(sequences_train, maxlen = max_len)\ndata_val = pad_sequences(sequences_val, maxlen = max_len)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:22:32.169948Z","iopub.execute_input":"2023-05-02T12:22:32.172335Z","iopub.status.idle":"2023-05-02T12:22:32.628692Z","shell.execute_reply.started":"2023-05-02T12:22:32.172299Z","shell.execute_reply":"2023-05-02T12:22:32.627709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ü§ñ Model\n---","metadata":{}},{"cell_type":"code","source":"# Create the model\nmodel = tf.keras.Sequential()\nmodel.add(Embedding(max_words, 16, input_length = max_len))\nmodel.add(GlobalAveragePooling1D())\nmodel.add(Dense(1, activation = 'sigmoid'))\n\n# Compile the model\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n\n# Checking summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:22:32.629972Z","iopub.execute_input":"2023-05-02T12:22:32.630311Z","iopub.status.idle":"2023-05-02T12:22:35.219392Z","shell.execute_reply.started":"2023-05-02T12:22:32.630282Z","shell.execute_reply":"2023-05-02T12:22:35.218641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit model\nhistory = model.fit(data_train, df_train['label'], epochs = 15, batch_size = 64, validation_data = (data_val, df_test['label']))","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:22:35.220626Z","iopub.execute_input":"2023-05-02T12:22:35.220969Z","iopub.status.idle":"2023-05-02T12:25:16.891876Z","shell.execute_reply.started":"2023-05-02T12:22:35.220937Z","shell.execute_reply":"2023-05-02T12:25:16.890940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the model\n---","metadata":{}},{"cell_type":"markdown","source":"## Accuracy","metadata":{}},{"cell_type":"code","source":"loss, accuracy = model.evaluate(data_val, df_test['label'], verbose = 0)\nprint('Accuracy: %f' % (accuracy*100))","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:25:16.893497Z","iopub.execute_input":"2023-05-02T12:25:16.893845Z","iopub.status.idle":"2023-05-02T12:25:17.493849Z","shell.execute_reply.started":"2023-05-02T12:25:16.893805Z","shell.execute_reply":"2023-05-02T12:25:17.492957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loss graph","metadata":{}},{"cell_type":"code","source":"# Loss graph\nplt.style.use('dark_background')\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\n\nplt.title('Model loss')\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'], loc = 'upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:25:17.495204Z","iopub.execute_input":"2023-05-02T12:25:17.495555Z","iopub.status.idle":"2023-05-02T12:25:17.741107Z","shell.execute_reply.started":"2023-05-02T12:25:17.495524Z","shell.execute_reply":"2023-05-02T12:25:17.740242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Accuracy graph","metadata":{}},{"cell_type":"code","source":"# Accuracy graph\nplt.style.use('dark_background')\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\n\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'], loc = 'lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:25:17.742618Z","iopub.execute_input":"2023-05-02T12:25:17.743239Z","iopub.status.idle":"2023-05-02T12:25:17.993206Z","shell.execute_reply.started":"2023-05-02T12:25:17.743208Z","shell.execute_reply":"2023-05-02T12:25:17.992314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üèÅ Thank you! Feel free to criticize! üèÅ¬∂","metadata":{}}]}